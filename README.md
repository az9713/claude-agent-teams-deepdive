# Observing Claude Opus 4.6 Agent Teams in Action

**Repository**: [github.com/az9713/claude-agent-teams-deepdive](https://github.com/az9713/claude-agent-teams-deepdive)

## What This Project Is

This is **not** primarily a TODO tracker application. The application is a vehicle.

The real goal of this project is to **observe, study, and document how Claude Code
Agent Teams behave** -- how they are created, how agents collaborate in parallel,
how work is divided and integrated, and how teams are shut down.

Equally important, this project studies **agent coordination mechanisms**: how do
agents that never talk to each other produce compatible code? The answer involves
hub-and-spoke communication topology, stub-first scaffolding, trait-based
compile-time contracts, file ownership boundaries, and a shared task list -- all
orchestrated by a single team lead. The case study documents every communication
channel, message count, and coordination pattern in detail.

The result is [AGENT_TEAM_CASE_STUDY.md](AGENT_TEAM_CASE_STUDY.md), a 900+ line
deep dive into Agent Team behavior with visual timelines, Gantt charts, agent roster,
inter-agent communication analysis, coordination patterns, and conflict resolution.

If you've heard about the new **Agent Teams** feature in Claude Code and wondered
*"What actually happens when multiple agents work together?"* or *"How do parallel
agents coordinate without stepping on each other?"* -- this project gives you a
concrete, real-world answer.

## Origin: The Claude Code Agent Teams Documentation Example

This project began with the first example prompt from the official
[Claude Code Agent Teams documentation](https://code.claude.com/docs/en/agent-teams):

> *"I'm designing a CLI tool that helps developers track TODO comments across
> their codebase. Create an agent team to explore this from different angles: one
> teammate on UX, one on technical architecture, one playing devil's advocate."*

We took this exact prompt and ran it -- first as a **design exploration** with three
research agents (UX, architecture, devil's advocate), and then as a full
**7-phase implementation** using teams of parallel builder agents. The result: a
complete Rust CLI application built from scratch by 11 coordinated agents in about
84 minutes -- an estimated **1.8x speedup** over sequential execution.

## What You'll Find Here

| File | What It Contains |
|------|-----------------|
| [AGENT_TEAM_CASE_STUDY.md](AGENT_TEAM_CASE_STUDY.md) | The main deliverable -- a 900+ line deep dive into Agent Team behavior with visual timelines, Gantt charts, agent roster, inter-agent communication analysis, coordination patterns, and lessons learned |
| `src/` | The complete todo-tracker CLI application (5,759 lines of Rust, 30 source files) |
| `tests/` | 173 passing tests (164 unit + 9 integration) |
| `.github/workflows/` | CI/CD pipelines generated by the distro-agent |
| `Dockerfile` | Alpine-based container image |

## How Agent Teams Were Used

Agent teams were employed in **both the design phase and all seven implementation phases**.

### Design Phase: Three-Angle Exploration

Following the documentation example, three research agents explored the concept simultaneously:

| Agent | Role | Output |
|-------|------|--------|
| UX researcher | User experience, CLI ergonomics, developer workflow | `exploration-ux.md` |
| Architect | Technical design, data model, performance strategy | `exploration-architecture.md` |
| Devil's advocate | Challenge assumptions, find gaps, stress-test ideas | `exploration-critique.md` |

Their combined output formed the 7-phase implementation plan.

### Implementation: Phased Parallel Execution

The implementation used a consistent pattern across all phases:

1. **Team lead** (Opus 4.6) creates scaffolding -- interfaces, stubs, shared types
2. **Builder agents** (Sonnet 4.5) implement independent modules in parallel
3. **Team lead** integrates, resolves conflicts, runs tests
4. Move to next phase

Here's how 11 agents were organized:

```
Phase 1 (MVP Scanner):       3 agents  [scanner] [discovery] [output]
Phase 2 (Core Features):     3 agents  [config] [formatters] [filter]
Phase 3 (Git Integration):   2 agents  [blame] [diff]          } ran in
Phase 4 (CI/Policy Engine):  1 agent   [policy]                } parallel
Phase 5 (Caching/Perf):      1 agent   [cache]                 } ran in
Phase 6 (Tree-sitter AST):   1 agent   [tree-sitter]           } parallel (bg task)
Phase 7 (Distribution):      1 agent   [distro]                } with Phase 5
```

### Phase Overlap: The Key Optimization

Not all phases must run sequentially. The team lead identified phases with
**no code dependencies on each other** and ran them simultaneously:

**Phases 3 + 4 overlapped**: Git integration (blame, diff) and CI policy engine
(policy checks, SARIF, GitHub Actions output) don't import from each other.
Three agents from two different phases ran at the same time:
```
~02:10 UTC ---- blame-agent (Phase 3) ------- done ~02:27
            \-- diff-agent  (Phase 3) ------- done ~02:26
             \- policy-agent (Phase 4) ------ done ~02:27
```

**Phases 5 + 7 overlapped**: SQLite caching is Rust code; distribution files are
YAML/Docker. Zero file overlap:
```
~02:35 UTC ---- cache-agent  (Phase 5) ------ done ~02:42
            \-- distro-agent (Phase 7) ------ done ~02:41
```

This overlap pattern reduced total build time from an estimated **~150 minutes
(sequential) to ~84 minutes actual -- a 1.8x parallel speedup**.

### The Parallel Speedup

```
Sequential (one agent at a time):          ~150 minutes estimated
                                           ████████████████████████████████████████

Parallel (agent teams with overlap):       ~84 minutes actual
                                           ██████████████████████

Speedup:                                   1.8x
```

The speedup comes from two sources:
1. **Within-phase parallelism**: 2-3 agents build independent modules simultaneously
   (e.g., scanner + discovery + formatter all at once)
2. **Cross-phase overlap**: Independent phases run at the same time
   (e.g., Git integration + CI policy engine share a time slot)

The speedup is less than the theoretical maximum because:
- Integration/wiring between phases is sequential (team lead is a bottleneck)
- Some agents finish faster than others (idle time waste)
- Scaffolding must be created before agents can start each phase

## What To Look For in the Case Study

The [AGENT_TEAM_CASE_STUDY.md](AGENT_TEAM_CASE_STUDY.md) is designed to let you
peek behind the scenes. Key sections:

### Under the Hood: Agent Lifecycle
- When and how each agent was **spawned** (with what prompt)
- What each agent **produced** (files, line counts, test counts)
- When each agent went **idle** and when it was **shut down**
- The full **Gantt-style timeline** showing all 11 agents' lifespans

### Inter-Agent Communication (NEW)
- **Hub-and-spoke topology**: All communication flows through the team lead; zero peer-to-peer messages between agents
- **Communication channel inventory**: 56 explicit messages, 40+ task updates, 12 spawn prompts
- **Implicit coordination**: How agents produce compatible code without talking to each other -- shared types, trait-based contracts, file system as read-only shared state
- **Shutdown protocol transcript**: The only true bidirectional dialog, with exact timestamps

### How Agents Coordinate
- **Stub-first scaffolding**: Why the lead creates interface stubs before spawning agents
- **File ownership boundaries**: Each agent owns specific files -- no two agents write the same file simultaneously
- **Phase overlap**: How the lead identifies independent phases and runs them in parallel
- **Background tasks**: When a full teammate is overkill and a lightweight background task is better

### When Things Go Wrong
- Multiple agents editing `cli.rs` and `main.rs` (different parts, same file)
- Return type mismatches between what one agent wrote and another expected
- tree-sitter API version differences the agent didn't know about
- "File modified since read" errors from concurrent access

### The Numbers
- 11 teammates + 1 background task agent + 1 team lead = 13 Claude instances
- 5,759 lines of Rust across 30 source files
- 173 passing tests
- **~84 minutes wall-clock time**
- **~1.8x parallel speedup vs sequential execution**

## The Application: todo-tracker (`todos`)

The vehicle for this study is a real, working CLI tool:

```bash
# Scan for TODOs
todos list --path ./src

# Filter by tag and author
todos list --tag=FIXME,HACK --author=alice

# JSON output for CI pipelines
todos list --format=json

# Git blame enrichment
todos blame --sort=date --since=2024-01-01

# Diff TODOs between branches
todos diff main..HEAD

# CI policy checks (exits non-zero on violations)
todos check --max-todos=50 --deny=NOCOMMIT --require-issue=FIXME

# SARIF output for GitHub Code Scanning
todos list --format=sarif > results.sarif

# High-precision mode (requires --features precise)
cargo run --features precise -- list --path ./src
```

### Build and Test

```bash
# Standard build
cargo build --release

# Run tests (141 unit + 9 integration)
cargo test

# Build with tree-sitter precision scanning (164 unit + 9 integration)
cargo test --features precise

# Install locally
cargo install --path .
```

## Requirements

- Rust 1.70+ (for building the application)
- Git (for blame/diff features)
- To study the Agent Team behavior itself: read [AGENT_TEAM_CASE_STUDY.md](AGENT_TEAM_CASE_STUDY.md)

## Enabling Agent Teams in Claude Code

Agent Teams are experimental. To try this yourself:

```json
// Add to your Claude Code settings.json:
{
  "env": {
    "CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS": "1"
  }
}
```

See the [official documentation](https://code.claude.com/docs/en/agent-teams) for
full details on team creation, display modes, task assignment, and best practices.

## License

This project is a study artifact. Use it however you like.
